{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097cbca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='ngpu', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--workers',type=int,default=8,help='Number of workers for dataloader')\n",
    "parser.add_argument('batch_size',type=int,default=128)\n",
    "parser.add_argument('n_class',type=int,default=27,help='Number of styles')\n",
    "parser.add_argument('n_class',type=int,default=27,help='Number of styles')\n",
    "parser.add_argument('image_size',type=int,default=64,help='Size of traning data')\n",
    "parser.add_argument('nc',type=int,default=3,help='Number of channels')\n",
    "parser.add_argument('nz',type=int,default=150,help='z latent vector')\n",
    "parser.add_argument('G_h_size',type=int,default=64,help='Size of feature maps in generator')\n",
    "parser.add_argument('D_h_size',type=int,default=32,help='Size of feature maps in discriminator')\n",
    "parser.add_argument('num_epochs',type=int,default=75)\n",
    "parser.add_argument('lr',type=float,default=0.0001)\n",
    "parser.add_argument('beta1 = 0.5',type=float,default=0.5,help='beta1 for adam')\n",
    "parser.add_argument('ngpu',type=int,default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5536f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0982e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') !=-1:\n",
    "        nn.init.normal_(m.weights.data,0.0,0.02)\n",
    "    elif classname.find('BatchNorm') !=-1:\n",
    "        nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "        nn.init.constant_(m.bias.data,0)\n",
    "\n",
    "def gaussian(ins, mean, stddev):\n",
    "    noise = Variable(ins.data.new(ins.size()).normal_(mean, stddev))\n",
    "    return ins + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f937d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN generator\n",
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(DCGAN_G,self).__init__()\n",
    "        self.label_emb = nn.Embedding(n_class,n_class)\n",
    "        self.ngpu = ngpu\n",
    "        main = torch.nn.Sequential()\n",
    "        \n",
    "        \n",
    "        # We need to know how many layers we will use at the beginning\n",
    "        mult = param.image_size // 8\n",
    "        \n",
    "        \n",
    "        ### Start block\n",
    "        # Z_size random numbers\n",
    "        main.add_module('Start-ConvTranspose2d',torch.nn.ConvTranspose2d(param.nz+n_class,param.G_h_size*mult,kernel_size=4,stride=1,padding=0,Bias=False))\n",
    "        if param.SELU:\n",
    "            main.add_module('Start-SELU',torch.nn.SELU(inplace=True))\n",
    "        else:\n",
    "            main.add_module('Start-BatchNorm2d',torch.nn.Batch2d(param.G_h_size*mult))\n",
    "            main.add_module('Start-ReLU',torch.nn.ReLU())\n",
    "        # Size = (G_h_size * mult)x 4 x4\n",
    "        \n",
    "        ### Middle block (Done until we reach  ? x image_size/2 x image_size/2)\n",
    "        i=1\n",
    "        while mult>1:\n",
    "            main.add_module('Middle-ConvTranspose2d [%d]'%i, torch.nn.ConvTranspose2d(param.G_h_size*mult,param.G_h_size*(mult//2),kernel_size=4,stride=2,padding=1,bias=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.G_h_size*(mult//2)))\n",
    "                main.add_module('Middle_ReLU [$d]'%i,torch.nn.ReLU(inplace=True))\n",
    "            # Size = (G_h_size * (mult/(2*i)))x8x8\n",
    "            mult = mult // 2\n",
    "            i+=1\n",
    "        \n",
    "        ### End block\n",
    "        # Size = G_h_size/2 x image_size/2\n",
    "        main.add_module('End-ConvTransposed2d', torch.nn.ConvTranspose2d(param.G_h_size,param.n_colors,kernel_size=4,stride=2,padding=1,bias=False))\n",
    "        main.add_module('End-Tanh',torch.nn.Tanh())\n",
    "        # Size = n_colors x image_size x image_size\n",
    "        self.main = main\n",
    "    \n",
    "    def forward(self,input,labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels).unsqueeze(2).unsqueeze(3),input),1)\n",
    "        if isinstance(gen_input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "            output = torch.nn.parallel.data_parallel(self.main,gen_input,range(param.n_gpu))\n",
    "        else:\n",
    "            output = self.main(gen_input)\n",
    "        output = img.view(img.size(0),*(param.n_colors,image_size,image_size))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a35b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCGAN discriminator ( using somewhat the reverse of the generator)\n",
    "class DCGAN_D(torch.nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(DCGAN_D,self).__init__()\n",
    "        main = torch.nn.Sequential()\n",
    "        self.ngpu = ngpu\n",
    "        self.label_emb = nn.Embedding(n_class,param.D_h_size*16*4)\n",
    "        \n",
    "        ### start block\n",
    "        # size = n_colors x image_size x image_size\n",
    "        main.add_module('Start-conv2d',torch.nn.Conv2d(param.n_colors,param.D_h_size,kernel=4,stride=2,padding=1,bias=False))\n",
    "        if param.SELU:\n",
    "            main.add_module('Start-SELU',torch.nn.SELU(inplace=True))\n",
    "        else:\n",
    "            main.add_module('Start-LeakyReLU',torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "        image_size_new = para.image_size // 2\n",
    "        # Size = D_h_size x image_size/2 x image_size/2\n",
    "        \n",
    "        ### Middle block (Done until we reach ? x 4 x4)\n",
    "        mult = 1\n",
    "        i=0\n",
    "        while image_size_new>4:\n",
    "            main.add_module('Middle-Conv2d [%d]'%i,torch.nn.Conv2d(param.D_h_size*mult,param.D_h_size*(2*mult),kernel_size=4,stride=2,padding=1,biase=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.D_h_size*(2*mult)))\n",
    "                main.add_module('Middle-LeakyReLU [%d]'%i,torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "            # Size = (D_h_size*(2*i)) x image_size/(2*i) x image_size/(2*i)\n",
    "            image_size_new = image_size_new // 2\n",
    "            mult *=2\n",
    "            i +=1\n",
    "            \n",
    "            ## End Block\n",
    "            # size = (D_h_size*mult) x 4 x4\n",
    "            main.add_module('End-Conv2d',torch.nn.Conv2d(param.D_h_size*mult,param.D_h_size*16,kernel_size=4,stride=1,padding=0,bias=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.D_h_size*(2*mult)))\n",
    "                main.add_module('Middle-LeakyReLU [%d]'%i,torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "            main.add_module('flatten',torch.nn.Flatten())\n",
    "#             main.add_module('Sigmoid',torch.nn.Sigmoid())\n",
    "            \n",
    "            # size = 1 x1 x1 (Is a real cat or not)\n",
    "            self.main = main\n",
    "            self.linear = torch.Sequential(\n",
    "                torch.nn.Linear(param.D_h_size*16*4*2,param.D_h_size*16),\n",
    "                torch.nn.SELU(inplace=True) if param.SELU else torch.nn.LeakyReLU(0.2,inplace=True),\n",
    "                torch.nn.Linear(param.D_h_size*16,1),\n",
    "                torch.nn.Sigmoid()\n",
    "            )\n",
    "            \n",
    "        def forward(self,input,labels):\n",
    "            linear_input = torch.cat((self.label_emb(labels),disct_out,1))\n",
    "            if isinstance(input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "                output = torch.nn.parallel.data_parallel(self.main,input,range(param.n_gpu))\n",
    "            else:\n",
    "                output = self.main(input)\n",
    "            \n",
    "            linear_input = torch.cat((self.label_emb(labels),disct_out,1))\n",
    "            if isinstance(input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "                output = torch.nn.parallel.data_parallel(self.linear,linear_input.squeeze(),range(param.n_gpu))\n",
    "            else:\n",
    "                output = self.linear(linear_input.squeeze())\n",
    "            \n",
    "            # Convert from 1 x 1 x 1 to 1 so that we can compare to given label (cat or not?)\n",
    "            return output.unsqueeze(2).unsquee(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd63d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(manualSeed)\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(manualSeed)\n\u001b[0;32m----> 6\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m()\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m ngpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "manualSeed = 999\n",
    "print('Random Seed: ',manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "dataloader = get_dataset()\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('off')\n",
    "plt.title('training Images')\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64],padding=2,normilize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a37c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DCGAN_G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m netG \u001b[38;5;241m=\u001b[39m \u001b[43mDCGAN_G\u001b[49m(param\u001b[38;5;241m.\u001b[39mn_gpu)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m netG\u001b[38;5;241m.\u001b[39mapply(weights_init)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(netG)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DCGAN_G' is not defined"
     ]
    }
   ],
   "source": [
    "netG = DCGAN_G(param.n_gpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "\n",
    "netD = DCGAN_D(param.n_gpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbb1d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m      2\u001b[0m example_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m----> 3\u001b[0m fixed_noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[43mn_class\u001b[49m\u001b[38;5;241m*\u001b[39mexample,param\u001b[38;5;241m.\u001b[39mnz,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      4\u001b[0m fixed_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mrepeat([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_class)],example_size)))\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m real_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_class' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "example_size = 4\n",
    "fixed_noise = torch.randn(n_class*example,param.nz,1,1,device=device)\n",
    "fixed_label = torch.tensor(list(np.repeat([i for i in range(n_class)],example_size))).type(torch.LongTensor).to(device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(),lr=param.lr,betas=(param.beta1,0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(),lr=param.lr,betas=(param.beta1,0.999))\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "img_save_path = 'images'\n",
    "os.makedirs(img_save_path,exist_ok=True)\n",
    "\n",
    "# Training Loop\n",
    "img_List = []\n",
    "G_losses = []\n",
    "D_losses =[]\n",
    "iters = 0\n",
    "\n",
    "print('starting Training Loop')\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(data,real_style_labels) in enumerate(dataloader,0):\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size),real_label,dtype=torch.float,device=device)\n",
    "        \n",
    "        real_style_labels = real_style_labels.to(device)\n",
    "        fake_style_labels = torch.tensor(np.random.choice(n_class,size=b_size)).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        # Forward pass real batch\n",
    "        output = netD(gaussian(real_cpu,mean=0,stddev=0.5*0.01**(param.epoch/num_epochs)),real_style_labels).view(-1)\n",
    "        \n",
    "        # Calc loss on real\n",
    "        errD_real = criterion(output,label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        # Train with all-fake batch\n",
    "        # Generate batch of laten vector\n",
    "        noise =torch.randn(b_size,nz,1,1,device=device)\n",
    "        # Generator fake image with C\n",
    "        fake = netG(noise,fake_style_labels)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        # classify all fake batch with D\n",
    "        output=netD(fake.detach(),fake_style_labels).view(-1)\n",
    "        # Calc D's loss on fake batch\n",
    "        errD_fake = criterion(output,label)\n",
    "        # Calculate gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # train G\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label) # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another pass of fake batch\n",
    "        output = netD(fake,fake_style_label).view(-1)\n",
    "        # Calculate loss for G\n",
    "        errG = criterion(output,label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if i%200==0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errG.item())\n",
    "        \n",
    "        # check how the generaot is doing by saving G's output on fixed noise\n",
    "        if (i == len(dataloader)-1):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise,fixed_label).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake,nrow=example_size,padding=2,normalize=True))\n",
    "            save_image(fake.data,img_save_path+'/%d-%d.png'%(epoch,iters),nrow=example_size,normalize=True)\n",
    "        iters+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472a9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
