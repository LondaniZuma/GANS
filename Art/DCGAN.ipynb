{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6586c0e-7901-4d88-ae47-9a67e72e1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--workers',type=int,default=8,help='Number of workers for dataloader')\n",
    "parser.add_argument('--batch_size',type=int,default=128)\n",
    "parser.add_argument('--n_class',type=int,default=27,help='Number of styles')\n",
    "parser.add_argument('--image_size',type=int,default=64,help='Size of traning data')\n",
    "parser.add_argument('--nc',type=int,default=3,help='Number of channels')\n",
    "parser.add_argument('--nz',type=int,default=150,help='z latent vector')\n",
    "parser.add_argument('--G_h_size',type=int,default=64,help='Size of feature maps in generator')\n",
    "parser.add_argument('--D_h_size',type=int,default=32,help='Size of feature maps in discriminator')\n",
    "parser.add_argument('--num_epochs',type=int,default=75)\n",
    "parser.add_argument('--lr',type=float,default=0.0001)\n",
    "parser.add_argument('--beta1 = 0.5',type=float,default=0.5,help='beta1 for adam')\n",
    "parser.add_argument('--ngpu',type=int,default=1)\n",
    "param, unknown = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531faae3-c324-4d9c-afdb-ff7988d56830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547c8ee0-b644-4e91-b337-456cb48e4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') !=-1:\n",
    "        nn.init.normal_(m.weights.data,0.0,0.02)\n",
    "    elif classname.find('BatchNorm') !=-1:\n",
    "        nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "        nn.init.constant_(m.bias.data,0)\n",
    "        \n",
    "\n",
    "        \n",
    "# DCGAN generator\n",
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(DCGAN_G,self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        main = torch.nn.Sequential()\n",
    "        \n",
    "        \n",
    "        # We need to know how many layers we will use at the beginning\n",
    "        mult = param.image_size // 8\n",
    "        \n",
    "        \n",
    "        ### Start block\n",
    "        # Z_size random numbers\n",
    "        main.add_module('Start-ConvTranspose2d',torch.nn.ConvTranspose2d(param.nz,param.G_h_size*mult,kernel_size=4,stride=1,padding=0,Bias=False))\n",
    "        if param.SELU:\n",
    "            main.add_module('Start-SELU',torch.nn.SELU(inplace=True))\n",
    "        else:\n",
    "            main.add_module('Start-BatchNorm2d',torch.nn.Batch2d(param.G_h_size*mult))\n",
    "            main.add_module('Start-ReLU',torch.nn.ReLU())\n",
    "        # Size = (G_h_size * mult)x 4 x4\n",
    "        \n",
    "        ### Middle block (Done until we reach  ? x image_size/2 x image_size/2)\n",
    "        i=1\n",
    "        while mult>1:\n",
    "            main.add_module('Middle-ConvTranspose2d [%d]'%i, torch.nn.ConvTranspose2d(param.G_h_size*mult,param.G_h_size*(mult//2),kernel_size=4,stride=2,padding=1,bias=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.G_h_size*(mult//2)))\n",
    "                main.add_module('Middle_ReLU [$d]'%i,torch.nn.ReLU(inplace=True))\n",
    "            # Size = (G_h_size * (mult/(2*i)))x8x8\n",
    "            mult = mult // 2\n",
    "            i+=1\n",
    "        \n",
    "        ### End block\n",
    "        # Size = G_h_size/2 x image_size/2\n",
    "        main.add_module('End-ConvTransposed2d', torch.nn.ConvTranspose2d(param.G_h_size,param.n_colors,kernel_size=4,stride=2,padding=1,bias=False))\n",
    "        main.add_module('End-Tanh',torch.nn.Tanh())\n",
    "        # Size = n_colors x image_size x image_size\n",
    "        self.main = main\n",
    "    \n",
    "    def forward(self,input):\n",
    "        if isinstance(input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "            output = torch.nn.parallel.data_parallel(self.main,input,range(param.n_gpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "    \n",
    "# DCGAN discriminator ( using somewhat the reverse of the generator)\n",
    "class DCGAN_D(torch.nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(DCGAN_D,self).__init__()\n",
    "        main = torch.nn.Sequential()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        ### start block\n",
    "        # size = n_colors x image_size x image_size\n",
    "        main.add_module('Start-conv2d',torch.nn.Conv2d(param.n_colors,param.D_h_size,kernel=4,stride=2,padding=1,bias=False))\n",
    "        if param.SELU:\n",
    "            main.add_module('Start-SELU',torch.nn.SELU(inplace=True))\n",
    "        else:\n",
    "            main.add_module('Start-LeakyReLU',torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "        image_size_new = para.image_size // 2\n",
    "        # Size = D_h_size x image_size/2 x image_size/2\n",
    "        \n",
    "        ### Middle block (Done until we reach ? x 4 x4)\n",
    "        mult = 1\n",
    "        i=0\n",
    "        while image_size_new>4:\n",
    "            main.add_module('Middle-Conv2d [%d]'%i,torch.nn.Conv2d(param.D_h_size*mult,param.D_h_size*(2*mult),kernel_size=4,stride=2,padding=1,biase=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.D_h_size*(2*mult)))\n",
    "                main.add_module('Middle-LeakyReLU [%d]'%i,torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "            # Size = (D_h_size*(2*i)) x image_size/(2*i) x image_size/(2*i)\n",
    "            image_size_new = image_size_new // 2\n",
    "            mult *=2\n",
    "            i +=1\n",
    "            \n",
    "            ## End Block\n",
    "            # size = (D_h_size*mult) x 4 x4\n",
    "            main.add_module('End-Conv2d',torch.nn.Conv2d(param.D_h_size*mult,1,kernel_size=4,stride=1,padding=0,bias=False))\n",
    "            main.add_module('Sigmoid',torch.nn.Sigmoid())\n",
    "            # size = 1 x1 x1 (Is a real cat or not)\n",
    "            self.main = main\n",
    "        def forward(self,input):\n",
    "            if isinstance(input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "                output = torch.nn.parallel.data_parallel(self.main,input,range(param.n_gpu))\n",
    "            else:\n",
    "                output = self.main(input)\n",
    "            \n",
    "            # Convert from 1 x 1 x 1 to 1 so that we can compare to given label (cat or not?)\n",
    "            return output.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560dcc2d-41ac-405b-8b0e-3724b1d2d7be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'ngpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1798/3942045165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'ngpu'"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "G = DCGAN_G()\n",
    "D = DCGAN_D()\n",
    "\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "# Load existing models\n",
    "if param.G_load !='':\n",
    "    G.load_state_dict(torch.load(param.G_load))\n",
    "if param.D_load !='':\n",
    "    D.load_state_dict(torch.load(param.D_load))\n",
    "    \n",
    "print(G)\n",
    "print(G,file=log_output)\n",
    "print(D)\n",
    "print(D,file=log_output)\n",
    "\n",
    "# criterion\n",
    "critirion = torch.nn.BCELoss()\n",
    "\n",
    "# # soon to be variables\n",
    "# x = torch.FloatTensor(param.batch_size,param.n_colors,param.image_size,param.image_size)\n",
    "# y = torch.FloatTensor(param.batch_size)\n",
    "# z = torch.FloatTensor(param.batch_size,param.z_size,1,1)\n",
    "# # This is to see during training, size and values won't change\n",
    "z_test = torch.FloatTensor(param.batch_size,param.z_size,1,1).normal_(0,1)\n",
    "\n",
    "# Everthing cuda\n",
    "G = G.to(device)\n",
    "D = D.to(device)\n",
    "criterion = criterion.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "z = z.to(device)\n",
    "z_test = z_test.to(device)\n",
    "    \n",
    "# # Now Variables\n",
    "# x = Variable(x)\n",
    "# y = Variable(y)\n",
    "# z = Variable(z)\n",
    "# z_test = Variable(z_test)\n",
    "\n",
    "# Based on DCGAN paper, they found using betas[0]=0.50 better.\n",
    "# betas[0] represent is the weight given to the previous mean of the gradient\n",
    "# betas[1] is the weight given to the previous variance of the gradient\n",
    "optimizerD = torch.optim.Adam(D.parameter(),lr=param.lr_D, betas=(param.beta1,0.999),weight_decay=param.weight_decay)\n",
    "optimizerG = torch.optim.Adam(G.parameter(),lr=param.lr_G, betas=(param.beta1,0.999),weight_decay=param.weight_decay)\n",
    "\n",
    "## fitting model\n",
    "for epoch in range(param.n_epoch):\n",
    "    \n",
    "    # Fake images saved\n",
    "    fake_test = G(z_test)\n",
    "    vutils.save_image(fake_test.data,'%s/run-%d/images/fake_samples_epoch%03d_extra%01d.png'%(param.output_folder,run,epoch,ext),normalize=True)\n",
    "    for ext in range(param.gen_extra_images):\n",
    "        z_extra = torch.FloatTensor(param.batch_size,param.z_size,1,1).normal_(0,1)\n",
    "        if param.cuda:\n",
    "            z_extra = z_extra.cuda()\n",
    "        fake_test = G(Variable(z_extra))\n",
    "        vutils.save_image(fake_test.data, '%s/run-%d/images/extra/fake_samples_epoch%3d_extra%01d.png'%(param.output_folder,run,epoch,ext),normalize=True)\n",
    "        \n",
    "    for i, data_batch in enumerate(dataset,0):\n",
    "        # Update D network\n",
    "        \n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "        # Train with real data\n",
    "        D.zero_grad()\n",
    "        # We can ignore labels since they are all cats\n",
    "        images,labels = data_batch\n",
    "        # Mostly necessary for the last one because if the N might not be a multiple of batch_size\n",
    "        current_batch_size = images.size(0)\n",
    "        if param.cuda:\n",
    "            images= images.cuda()\n",
    "        # Transfer batch of images to x\n",
    "        x.data.resize_as_(images).copy_(images)\n",
    "        # y is now a vector of size current_batch_size filled with 1\n",
    "        y.data.resize_(current_batch_size).fill_(1)\n",
    "        y_pred = D(x)\n",
    "        errD_real = criterion(y_pred,y)\n",
    "        errD_real.backward()\n",
    "        # Var has data and gradient element, we keep the mean of the data element\n",
    "        D_real = y_pred.data.mean()\n",
    "        \n",
    "        # Train with fake data\n",
    "        z.data.resize_(current_batch_size,param.z_size,1,1).normal_(0,1)\n",
    "        x_fake = G(z)\n",
    "        y.data.resize_(current_batch_size).fill_(0)\n",
    "        # Detach y_pred from the neural network G and put it inside D\n",
    "        y_pred_fake = D(x_fake.detach())\n",
    "        errD_fake = criterion(y_pred_fake,y)\n",
    "        errD_fake.backward()\n",
    "        D_fake = y_pred_fake.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Update G net work\n",
    "        # make it tiny bit faster\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        G.zero_grad()\n",
    "        # Generator wants to foll discriminaor so it wants to minimize loss of discriminator assuming label is True\n",
    "        y.data.resize_(current_batch_size).fill_(1)\n",
    "        y_pred_fake = D(x_fake)\n",
    "        errG = criterion(y_pred_fake,y)\n",
    "        errG.backward(retain_graph=True)\n",
    "        D_G = y_pred_fake.data.mean()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        current_step = i + epoch*len(dataset)\n",
    "        # Log results so we can see them in TensorBoard after\n",
    "        log_value('errD',errD.data[0],current_step)\n",
    "        log_value('errG',errG.data[0],current_step)\n",
    "        \n",
    "        if i%50 ==0:\n",
    "            end = time.time()\n",
    "            fmt = '[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f/%.4f time:%.4f'\n",
    "            s = fmt%(epoch,param.n_epoch,i,len(dataset),errD.data[0],errG.data[0],D_real,D_fake,D_G,end-start)\n",
    "            print(s)\n",
    "            print(s,file=log_output)\n",
    "            \n",
    "    # save every epoch\n",
    "    fmt = '%s/run-%d/models/%s_epoch_%d.pth'\n",
    "    if epoch%25==0:\n",
    "        torch.save(G.state_dict(),mft%(param.output_folder, run, 'G',epoch))\n",
    "        torch.save(D.state_dict(), fmt%(param.output_folder, run,'D',epoch))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651a4921-38b2-4a5a-8da3-eeb29df7cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954b6e40-c414-43e8-9d20-30791056f9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5138403f-e1dd-4b9e-b6ee-c1456d1fb0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla K80 (UUID: GPU-522b75e0-87d4-687a-39ba-4f2cf7774ff8)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --list-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37def53d-6c43-4604-ae49-0a0794261b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for jovyan: \n"
     ]
    }
   ],
   "source": [
    "!sudo lshw -C video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f277b67a-d232-4a90-85b1-f8717be44b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name --format=csv,noheader | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7784a10d-ca82-4709-a634-e1692c5962e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo | grep processor | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee65095-77a8-4677-ae58-a4e3ab164374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat /proc/cpuinfo | grep 'core id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e80437-d014-4954-97d1-0eb88579a596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
