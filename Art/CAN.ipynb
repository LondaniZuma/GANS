{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158763ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='ngpu', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--workers',type=int,default=8,help='Number of workers for dataloader')\n",
    "parser.add_argument('batch_size',type=int,default=128)\n",
    "parser.add_argument('n_class',type=int,default=27,help='Number of styles')\n",
    "parser.add_argument('n_class',type=int,default=27,help='Number of styles')\n",
    "parser.add_argument('image_size',type=int,default=64,help='Size of traning data')\n",
    "parser.add_argument('nc',type=int,default=3,help='Number of channels')\n",
    "parser.add_argument('nz',type=int,default=150,help='z latent vector')\n",
    "parser.add_argument('G_h_size',type=int,default=64,help='Size of feature maps in generator')\n",
    "parser.add_argument('D_h_size',type=int,default=32,help='Size of feature maps in discriminator')\n",
    "parser.add_argument('num_epochs',type=int,default=75)\n",
    "parser.add_argument('lr',type=float,default=0.0001)\n",
    "parser.add_argument('beta1 = 0.5',type=float,default=0.5,help='beta1 for adam')\n",
    "parser.add_argument('ngpu',type=int,default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18383056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') !=-1:\n",
    "        nn.init.normal_(m.weights.data,0.0,0.02)\n",
    "    elif classname.find('BatchNorm') !=-1:\n",
    "        nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "        nn.init.constant_(m.bias.data,0)\n",
    "        \n",
    "\n",
    "        \n",
    "# DCGAN generator\n",
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(DCGAN_G,self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        main = torch.nn.Sequential()\n",
    "        \n",
    "        \n",
    "        # We need to know how many layers we will use at the beginning\n",
    "        mult = param.image_size // 8\n",
    "        \n",
    "        \n",
    "        ### Start block\n",
    "        # Z_size random numbers\n",
    "        main.add_module('Start-ConvTranspose2d',torch.nn.ConvTranspose2d(param.nz,param.G_h_size*mult,kernel_size=4,stride=1,padding=0,Bias=False))\n",
    "        if param.SELU:\n",
    "            main.add_module('Start-SELU',torch.nn.SELU(inplace=True))\n",
    "        else:\n",
    "            main.add_module('Start-BatchNorm2d',torch.nn.Batch2d(param.G_h_size*mult))\n",
    "            main.add_module('Start-ReLU',torch.nn.ReLU())\n",
    "        # Size = (G_h_size * mult)x 4 x4\n",
    "        \n",
    "        ### Middle block (Done until we reach  ? x image_size/2 x image_size/2)\n",
    "        i=1\n",
    "        while mult>1:\n",
    "            main.add_module('Middle-ConvTranspose2d [%d]'%i, torch.nn.ConvTranspose2d(param.G_h_size*mult,param.G_h_size*(mult//2),kernel_size=4,stride=2,padding=1,bias=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.G_h_size*(mult//2)))\n",
    "                main.add_module('Middle_ReLU [$d]'%i,torch.nn.ReLU(inplace=True))\n",
    "            # Size = (G_h_size * (mult/(2*i)))x8x8\n",
    "            mult = mult // 2\n",
    "            i+=1\n",
    "        \n",
    "        ### End block\n",
    "        # Size = G_h_size/2 x image_size/2\n",
    "        main.add_module('End-ConvTransposed2d', torch.nn.ConvTranspose2d(param.G_h_size,param.n_colors,kernel_size=4,stride=2,padding=1,bias=False))\n",
    "        main.add_module('End-Tanh',torch.nn.Tanh())\n",
    "        # Size = n_colors x image_size x image_size\n",
    "        self.main = main\n",
    "    \n",
    "    def forward(self,input):\n",
    "        if isinstance(input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "            output = torch.nn.parallel.data_parallel(self.main,input,range(param.n_gpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "    \n",
    "# DCGAN discriminator ( using somewhat the reverse of the generator)\n",
    "class DCGAN_D(torch.nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(DCGAN_D,self).__init__()\n",
    "        main = torch.nn.Sequential()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        ### start block\n",
    "        # size = n_colors x image_size x image_size\n",
    "        main.add_module('Start-conv2d',torch.nn.Conv2d(param.n_colors,param.D_h_size,kernel=4,stride=2,padding=1,bias=False))\n",
    "        if param.SELU:\n",
    "            main.add_module('Start-SELU',torch.nn.SELU(inplace=True))\n",
    "        else:\n",
    "            main.add_module('Start-LeakyReLU',torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "        image_size_new = para.image_size // 2\n",
    "        # Size = D_h_size x image_size/2 x image_size/2\n",
    "        \n",
    "        ### Middle block (Done until we reach ? x 4 x4)\n",
    "        mult = 1\n",
    "        i=0\n",
    "        while image_size_new>4:\n",
    "            main.add_module('Middle-Conv2d [%d]'%i,torch.nn.Conv2d(param.D_h_size*mult,param.D_h_size*(2*mult),kernel_size=4,stride=2,padding=1,biase=False))\n",
    "            if param.SELU:\n",
    "                main.add_module('Middle-SELU [%d]'%i,torch.nn.SELU(inplace=True))\n",
    "            else:\n",
    "                main.add_module('Middle-BatchNorm2d [%d]'%i,torch.nn.BatchNorm2d(param.D_h_size*(2*mult)))\n",
    "                main.add_module('Middle-LeakyReLU [%d]'%i,torch.nn.LeakyReLU(0.2,inplace=True))\n",
    "            # Size = (D_h_size*(2*i)) x image_size/(2*i) x image_size/(2*i)\n",
    "            image_size_new = image_size_new // 2\n",
    "            mult *=2\n",
    "            i +=1\n",
    "            \n",
    "            ## End Block\n",
    "            # size = (D_h_size*mult) x 4 x4\n",
    "            main.add_module('End-Conv2d',torch.nn.Conv2d(param.D_h_size*mult,1,kernel_size=4,stride=1,padding=0,bias=False))\n",
    "            main.add_module('Sigmoid',torch.nn.Sigmoid())\n",
    "            # size = 1 x1 x1 (Is a real cat or not)\n",
    "            self.main = main\n",
    "            self.mult = mult\n",
    "            \n",
    "            self.discriminate = nn.Sequential(\n",
    "                nn.Conv2d(param.D_h_size*mult,1,kernel_size=4,stride=1,padding=0,bias=False),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "            \n",
    "            # test these two setting\n",
    "            self.classify = nn.Sequential(\n",
    "                nn.Conv2d(param.D_h_size*mult,n_class,kernel_size=4,stride=1,padding=0,bias=False)\n",
    "            )\n",
    "#             self.classify = nn.Sequential(\n",
    "#                 nn.Linear(param.D_h_size*mult*4*4,1024),\n",
    "#                 nn.LeakyReLU(0.2,inplace=True),\n",
    "#                 nn.Linear(1024,512),\n",
    "#                 nn.LeakyReLU(0.2,inplace=True),\n",
    "#                 nn.Linear(512,n_class),\n",
    "#                 nn.Softmax(dim=1)\n",
    "#             )\n",
    "            \n",
    "        def forward(self,input):\n",
    "            if isinstance(input.data,torch.cuda.FloatTensor) and param.n_gpu>1:\n",
    "                output = torch.nn.parallel.data_parallel(self.main,input,range(param.n_gpu))\n",
    "                d_out = torch.nn.parallel.data_parallel(self.discriminate,output,range(param.n_gpu))\n",
    "                c_out = torch.nn.parallel.data_parallel(self.classify,output,range(param.n_gpu))\n",
    "                # second option\n",
    "                d_out = torch.nn.parallel.data_parallel(self.discriminate,output,range(param.n_gpu)).view(-1,1)\n",
    "                c_out = torch.nn.parallel.data_parallel(self.classify,output.view(-1,param.D_h_size*self.mult*4*4),range(param.n_gpu))\n",
    "            else:\n",
    "                output = self.main(input)\n",
    "                d_out = self.discriminate(output)\n",
    "                c_out = self.classify(output)\n",
    "                # second option\n",
    "                d_out = self.discriminate(output).view(-1,1)\n",
    "                c_out = self.classify(output.view(-1,param.D_h_size*self.mult*4*4))\n",
    "            \n",
    "            # Convert from 1 x 1 x 1 to 1 so that we can compare to given label (cat or not?)\n",
    "            return d_out,c_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53139cb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataloader_wikiart'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manimation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01manimation\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataloader_wikiart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_style\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m     20\u001b[0m manualSeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m999\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataloader_wikiart'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from dataloader_wikiart import *\n",
    "from model_style import * \n",
    "\n",
    "manualSeed = 999\n",
    "print(\"Random Seed: \",manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Create the dataloader\n",
    "# dataset = StyleDataset()\n",
    "# dataloader = DataLoader(dataset,batch_size,shuffle=True,num_workers=workers,pin_memory=True)\n",
    "dataloader = get_dataset()\n",
    "\n",
    "# Dataloader usage in training loop:\n",
    "# for i,(data,target,label) in enumerate(dataloader): data=image, target=onehot encoded style,label=style\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b84213",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot some training images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m real_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mdataloader\u001b[49m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ba1a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the generator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m netG \u001b[38;5;241m=\u001b[39m \u001b[43mGenerator\u001b[49m(ngpu)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # Handle multi-gpu if desired\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# if (device.type == 'cuda') and (ngpu > 1):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     netG = nn.DataParallel(netG, list(range(ngpu)))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the weights_init function to randomly initialize all weights\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#  to mean=0, stdev=0.2.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m netG\u001b[38;5;241m.\u001b[39mapply(weights_init)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# # Handle multi-gpu if desired\n",
    "# if (device.type == 'cuda') and (ngpu > 1):\n",
    "#     netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4baa6f0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the Discriminator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m netD \u001b[38;5;241m=\u001b[39m \u001b[43mDiscriminator\u001b[49m(ngpu)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # Handle multi-gpu if desired\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# if (device.type == 'cuda') and (ngpu > 1):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     netD = nn.DataParallel(netD, list(range(ngpu)))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Apply the weights_init function to randomly initialize all weights\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#  to mean=0, stdev=0.2.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m netD\u001b[38;5;241m.\u001b[39mapply(weights_init)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# # Handle multi-gpu if desired\n",
    "# if (device.type == 'cuda') and (ngpu > 1):\n",
    "#     netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5cd01e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'CrossEntropLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m----> 2\u001b[0m criterion_style \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropLoss\u001b[49m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## create batch of latent vectors that we will use to visualize\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the progression of the generator\u001b[39;00m\n\u001b[1;32m      6\u001b[0m fixed_noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m,param\u001b[38;5;241m.\u001b[39mnz,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'CrossEntropLoss'"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "criterion_style = nn.CrossEntropLoss()\n",
    "\n",
    "## create batch of latent vectors that we will use to visualize\n",
    "# the progression of the generator\n",
    "fixed_noise = torch.randn(64,param.nz,1,1,device=device)\n",
    "\n",
    "# establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(),lr=lr,betas=(beta1,0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(),lr=lr,betas=(beta1,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7ba2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training Loop...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# For each epoch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnum_epochs\u001b[49m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i,(data,style_label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader,\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# update D: maximize log(D(x)) + log(1-D(G(z)))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Train with all-real batch\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         netD\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "# lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "entropies = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(data,style_label) in enumerate(dataloader,0):\n",
    "        # update D: maximize log(D(x)) + log(1-D(G(z)))\n",
    "        # Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        style_label = style_label.to(device)\n",
    "        real_cpu = data.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,),real_label , dtype=torch.float,device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output,output_style = netD(real_cpu)\n",
    "        # Calculate loss on real\n",
    "        errD_real = criterion(output,label)\n",
    "        errD_real = errD_real + criterion_style(output_style.squeeze(),style_label.squeeze())\n",
    "        # Calc gradients for D\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        ## Train with fake\n",
    "        noise = torch.randn(b_size,param.nz,1,1,device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill(fake_label)\n",
    "        #classify all fake image batch D\n",
    "        output,output_style = netD(fake.detach())\n",
    "        # Calculate D loss on fake\n",
    "        errD_fake = criterion(output,label)\n",
    "        # calc the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD=errD_real + errD_fake\n",
    "        #update D\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Update G: maximize log(D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)# fake labels are real for generator cost\n",
    "        output,output_style = netD(fake)\n",
    "        # Uniform cross entropy\n",
    "        logsoftmax=nn.LogSoftmax(dim=1)\n",
    "        unif = torch.full((data.shape[0],n_class),1/n_class)\n",
    "        unif = unif.to(device)\n",
    "        # Calc G's loss based on this output\n",
    "        \n",
    "        errG = criterion(output,label)\n",
    "        errG = errG + torch.mean(-torch.sum(unif*logsoftmax(output_style),1))\n",
    "        # Calc gradients for \n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        #Update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        style_entropy = -1*(nn.functional.softmax(output_style,dim=1)*nn.functional.log_softmax(out_style,dim=1))\n",
    "        style_entropy = style_entropy.sum(dim=1).mean()/torch.log(torch.tensor(n_class).float())\n",
    "        \n",
    "        # output training stats\n",
    "        if i%50==0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f\\t Entropy: %.4f'\n",
    "                 %(epoch,num_epochs,i,len(dataloader),\n",
    "                  errD.item(),errG.item(),D_x,D_G_z1,D_G_z2,style_entropy))\n",
    "            \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        entropies.append(style_entropy)\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if(iters%500==0) or ((epoch==num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake,padding=2, normalize=True))\n",
    "            \n",
    "        iters +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119cee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
