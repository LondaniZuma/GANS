{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfe8654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_size IMAGE_SIZE]\n",
      "                             [--batch_size BATCH_SIZE] [--n_colors N_COLORS]\n",
      "                             [--z_size Z_SIZE] [--G_h_size G_H_SIZE]\n",
      "                             [--D_h_size D_H_SIZE] [--lr_D LR_D] [--lr_G LR_G]\n",
      "                             [--n_epoch N_EPOCH] [--n_critic N_CRITIC]\n",
      "                             [--clip CLIP] [--SELU SELU] [--seed SEED]\n",
      "                             [--input_folder INPUT_FOLDER]\n",
      "                             [--output_folder OUTPUT_FOLDER] [--G_load G_LOAD]\n",
      "                             [--D_load D_LOAD] [--cuda CUDA] [--n_gpu N_GPU]\n",
      "                             [--n_workers N_WORKERS]\n",
      "                             [--gen_extra_images GEN_EXTRA_IMAGES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/lonzuma/Library/Jupyter/runtime/kernel-628d0935-1f19-4fdf-b963-6f716a1bf0db.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--image_size', type=int, default=64)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--n_colors', type=int, default=3)\n",
    "parser.add_argument('--z_size', type=int, default=100) # DCGAN paper original value\n",
    "parser.add_argument('--G_h_size', type=int, default=64, help='Number of hidden nodes in the Generator. Too small leads to bad results, too big blows up the GPU RAM.') # DCGAN paper original value\n",
    "parser.add_argument('--D_h_size', type=int, default=64, help='Number of hidden nodes in the Discriminator. Too small leads to bad results, too big blows up the GPU RAM.') # DCGAN paper original value\n",
    "parser.add_argument('--lr_D', type=float, default=.00005, help='Discriminator learning rate') # WGAN original value\n",
    "parser.add_argument('--lr_G', type=float, default=.00005, help='Generator learning rate')\n",
    "parser.add_argument('--n_epoch', type=int, default=500000)\n",
    "parser.add_argument('--n_critic', type=int, default=5, help='Number of training with D before training G') # WGAN original value\n",
    "parser.add_argument('--clip', type=float, default=.01, help='Clipping value') # WGAN original value\n",
    "parser.add_argument('--SELU', type=bool, default=False, help='Using scaled exponential linear units (SELU) which are self-normalizing instead of ReLU with BatchNorm. This improves stability.')\n",
    "parser.add_argument('--seed', type=int)\n",
    "parser.add_argument('--input_folder', default='/home/alexia/Datasets/Meow_64x64', help='input folder')\n",
    "parser.add_argument('--output_folder', default='/home/alexia/Output/WGAN', help='output folder')\n",
    "parser.add_argument('--G_load', default='', help='Full path to Generator model to load (ex: /home/output_folder/run-5/models/G_epoch_11.pth)')\n",
    "parser.add_argument('--D_load', default='', help='Full path to Discriminator model to load (ex: /home/output_folder/run-5/models/D_epoch_11.pth)')\n",
    "parser.add_argument('--cuda', type=bool, default=True, help='enables cuda')\n",
    "parser.add_argument('--n_gpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--n_workers', type=int, default=2, help='Number of subprocess to use to load the data. Use at least two or the number of cpu cores - 1.')\n",
    "parser.add_argument('--gen_extra_images', type=int, default=0, help='Every 50 generator iterations, generate additional images with \"batch_size\" random fake cats.')\n",
    "param = parser.parse_args()\n",
    "\n",
    "## Imports\n",
    "\n",
    "# Time\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Check folder run-i for all i=0,1,... until it finds run-j which does not exists, then creates a new folder run-j\n",
    "import os\n",
    "run = 0\n",
    "base_dir = f\"{param.output_folder}/run-{run}\"\n",
    "while os.path.exists(base_dir):\n",
    "\trun += 1\n",
    "\tbase_dir = f\"{param.output_folder}/run-{run}\"\n",
    "os.mkdir(base_dir)\n",
    "logs_dir = f\"{base_dir}/logs\"\n",
    "os.mkdir(logs_dir)\n",
    "os.mkdir(f\"{base_dir}/images\")\n",
    "os.mkdir(f\"{base_dir}/models\")\n",
    "if param.gen_extra_images > 0:\n",
    "\tos.mkdir(f\"{base_dir}/images/extra\")\n",
    "\n",
    "# where we save the output\n",
    "log_output = open(f\"{logs_dir}/log.txt\", 'w')\n",
    "print(param)\n",
    "print(param, file=log_output)\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# For plotting the Loss of D and G using tensorboard\n",
    "from tensorboard_logger import configure, log_value\n",
    "configure(logs_dir, flush_secs=5)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transf\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "if param.cuda:\n",
    "\timport torch.backends.cudnn as cudnn\n",
    "\tcudnn.benchmark = True\n",
    "\n",
    "# To see images\n",
    "from IPython.display import Image\n",
    "to_img = transf.ToPILImage()\n",
    "\n",
    "## Setting seed\n",
    "import random\n",
    "if param.seed is None:\n",
    "\tparam.seed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", param.seed)\n",
    "print(\"Random Seed: \", param.seed, file=log_output)\n",
    "random.seed(param.seed)\n",
    "torch.manual_seed(param.seed)\n",
    "if param.cuda:\n",
    "\ttorch.cuda.manual_seed_all(param.seed)\n",
    "\n",
    "## Transforming images\n",
    "trans = transf.Compose([\n",
    "\ttransf.Scale((param.image_size, param.image_size)),\n",
    "\t# This makes it into [0,1]\n",
    "\ttransf.ToTensor(),\n",
    "\t# This makes it into [-1,1] so tanh will work properly\n",
    "\ttransf.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "## Importing dataset\n",
    "data = dset.ImageFolder(root=param.input_folder, transform=trans)\n",
    "\n",
    "# Loading data in batch\n",
    "dataset = torch.utils.data.DataLoader(data, batch_size=param.batch_size, shuffle=True, num_workers=param.n_workers)\n",
    "\n",
    "## Models\n",
    "\n",
    "## Models\n",
    "# The number of layers is implicitly determined by the image size\n",
    "# image_size = (4,8,16,32,64, 128, 256, 512, 1024) leads to n_layers = (1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
    "# The more layers the bigger the neural get so it's best to decrease G_h_size and D_h_size when the image input is bigger\n",
    "\n",
    "# DCGAN generator\n",
    "class DCGAN_G(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DCGAN_G, self).__init__()\n",
    "\t\tmain = torch.nn.Sequential()\n",
    "\n",
    "\t\t# We need to know how many layers we will use at the beginning\n",
    "\t\tmult = param.image_size // 8\n",
    "\n",
    "\t\t### Start block\n",
    "\t\t# Z_size random numbers\n",
    "\t\tmain.add_module('Start-ConvTranspose2d', torch.nn.ConvTranspose2d(param.z_size, param.G_h_size * mult, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "\t\tif param.SELU:\n",
    "\t\t\tmain.add_module('Start-SELU', torch.nn.SELU(inplace=True))\n",
    "\t\telse:\n",
    "\t\t\tmain.add_module('Start-BatchNorm2d', torch.nn.BatchNorm2d(param.G_h_size * mult))\n",
    "\t\t\tmain.add_module('Start-ReLU', torch.nn.ReLU())\n",
    "\t\t# Size = (G_h_size * mult) x 4 x 4\n",
    "\n",
    "\t\t### Middle block (Done until we reach ? x image_size/2 x image_size/2)\n",
    "\t\ti = 1\n",
    "\t\twhile mult > 1:\n",
    "\t\t\tmain.add_module('Middle-ConvTranspose2d [%d]' % i, torch.nn.ConvTranspose2d(param.G_h_size * mult, param.G_h_size * (mult//2), kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\t\tif param.SELU:\n",
    "\t\t\t\tmain.add_module('Middle-SELU [%d]' % i, torch.nn.SELU(inplace=True))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmain.add_module('Middle-BatchNorm2d [%d]' % i, torch.nn.BatchNorm2d(param.G_h_size * (mult//2)))\n",
    "\t\t\t\tmain.add_module('Middle-ReLU [%d]' % i, torch.nn.ReLU())\n",
    "\t\t\t# Size = (G_h_size * (mult/(2*i))) x 8 x 8\n",
    "\t\t\tmult = mult // 2\n",
    "\t\t\ti += 1\n",
    "\n",
    "\t\t### End block\n",
    "\t\t# Size = G_h_size x image_size/2 x image_size/2\n",
    "\t\tmain.add_module('End-ConvTranspose2d', torch.nn.ConvTranspose2d(param.G_h_size, param.n_colors, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\tmain.add_module('End-Tanh', torch.nn.Tanh())\n",
    "\t\t# Size = n_colors x image_size x image_size\n",
    "\t\tself.main = main\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tif isinstance(input.data, torch.cuda.FloatTensor) and param.n_gpu > 1:\n",
    "\t\t\toutput = torch.nn.parallel.data_parallel(self.main, input, range(param.n_gpu))\n",
    "\t\telse:\n",
    "\t\t\toutput = self.main(input)\n",
    "\t\treturn output\n",
    "\n",
    "# DCGAN discriminator (using somewhat the reverse of the generator)\n",
    "class DCGAN_D(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DCGAN_D, self).__init__()\n",
    "\t\tmain = torch.nn.Sequential()\n",
    "\n",
    "\t\t### Start block\n",
    "\t\t# Size = n_colors x image_size x image_size\n",
    "\t\tmain.add_module('Start-Conv2d', torch.nn.Conv2d(param.n_colors, param.D_h_size, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\tif param.SELU:\n",
    "\t\t\tmain.add_module('Start-SELU', torch.nn.SELU(inplace=True))\n",
    "\t\telse:\n",
    "\t\t\tmain.add_module('Start-LeakyReLU', torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\t\timage_size_new = param.image_size // 2\n",
    "\t\t# Size = D_h_size x image_size/2 x image_size/2\n",
    "\n",
    "\t\t### Middle block (Done until we reach ? x 4 x 4)\n",
    "\t\tmult = 1\n",
    "\t\ti = 0\n",
    "\t\twhile image_size_new > 4:\n",
    "\t\t\tmain.add_module('Middle-Conv2d [%d]' % i, torch.nn.Conv2d(param.D_h_size * mult, param.D_h_size * (2*mult), kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\t\tif param.SELU:\n",
    "\t\t\t\tmain.add_module('Middle-SELU [%d]' % i, torch.nn.SELU(inplace=True))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmain.add_module('Middle-BatchNorm2d [%d]' % i, torch.nn.BatchNorm2d(param.D_h_size * (2*mult)))\n",
    "\t\t\t\tmain.add_module('Middle-LeakyReLU [%d]' % i, torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\t\t\t# Size = (D_h_size*(2*i)) x image_size/(2*i) x image_size/(2*i)\n",
    "\t\t\timage_size_new = image_size_new // 2\n",
    "\t\t\tmult = mult*2\n",
    "\t\t\ti += 1\n",
    "\n",
    "\t\t### End block\n",
    "\t\t# Size = (D_h_size * mult) x 4 x 4\n",
    "\t\tmain.add_module('End-Conv2d', torch.nn.Conv2d(param.D_h_size * mult, 1, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "\t\t# Note: No more sigmoid in WGAN, we take the mean now\n",
    "\t\t# Size = 1 x 1 x 1 (Is a real cat or not?)\n",
    "\t\tself.main = main\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tif isinstance(input.data, torch.cuda.FloatTensor) and param.n_gpu > 1:\n",
    "\t\t\toutput = torch.nn.parallel.data_parallel(self.main, input, range(param.n_gpu))\n",
    "\t\telse:\n",
    "\t\t\toutput = self.main(input)\n",
    "\t\t# From batch_size x 1 x 1 to 1 x 1 x 1 by taking the mean (DCGAN used the sigmoid instead before)\n",
    "\t\toutput = output.mean(0)\n",
    "\t\t# Convert from 1 x 1 x 1 to 1 so that we can compare to given label (cat or not?)\n",
    "\t\treturn output.view(1)\n",
    "\n",
    "## Weights init function, DCGAN use 0.02 std\n",
    "def weights_init(m):\n",
    "\tclassname = m.__class__.__name__\n",
    "\tif classname.find('Conv') != -1:\n",
    "\t\tm.weight.data.normal_(0.0, 0.02)\n",
    "\telif classname.find('BatchNorm') != -1:\n",
    "\t\t# Estimated variance, must be around 1\n",
    "\t\tm.weight.data.normal_(1.0, 0.02)\n",
    "\t\t# Estimated mean, must be around 0\n",
    "\t\tm.bias.data.fill_(0)\n",
    "\n",
    "## Initialization\n",
    "G = DCGAN_G()\n",
    "D = DCGAN_D()\n",
    "\n",
    "# Initialize weights\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "# Load existing models\n",
    "if param.G_load != '':\n",
    "\tG.load_state_dict(torch.load(param.G_load))\n",
    "if param.D_load != '':\n",
    "\tD.load_state_dict(torch.load(param.D_load))\n",
    "\n",
    "print(G)\n",
    "print(G, file=log_output)\n",
    "print(D)\n",
    "print(D, file=log_output)\n",
    "\n",
    "# Soon to be variables\n",
    "x = torch.FloatTensor(param.batch_size, param.n_colors, param.image_size, param.image_size)\n",
    "z = torch.FloatTensor(param.batch_size, param.z_size, 1, 1)\n",
    "# This is to see during training, size and values won't change\n",
    "z_test = torch.FloatTensor(param.batch_size, param.z_size, 1, 1).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "one_neg = one * -1\n",
    "\n",
    "# Everything cuda\n",
    "if param.cuda:\n",
    "\tG = G.cuda()\n",
    "\tD = D.cuda()\n",
    "\tx = x.cuda()\n",
    "\tz = z.cuda()\n",
    "\tz_test = z_test.cuda()\n",
    "\tone, one_neg = one.cuda(), one_neg.cuda()\n",
    "\n",
    "# Now Variables\n",
    "x = Variable(x)\n",
    "z = Variable(z)\n",
    "z_test = Variable(z_test)\n",
    "\n",
    "# Optimizer\n",
    "optimizerD = torch.optim.RMSprop(D.parameters(), lr=param.lr_D)\n",
    "optimizerG = torch.optim.RMSprop(G.parameters(), lr=param.lr_G)\n",
    "\n",
    "## Fitting model\n",
    "\n",
    "gen_iterations = 0\n",
    "for epoch in range(param.n_epoch):\n",
    "    # Fake images saved\n",
    "    if get_iterations %50 ==0:\n",
    "        fake_test = G(z_test)\n",
    "        vutils.save_image(fake_test.data, '%s/run-%d/images/fake_samples_iter%03d.png' % (param.output_folder, run, gen_iterations/50), normalize=True)\n",
    "        for ext in range(param.gen_extra_images):\n",
    "            z_extra = torch.FloatTensor(param.batch_size,param.z_size,1,1).normal_(0,1)\n",
    "            if param.cuda:\n",
    "                z_extra = z_extra.cuda()\n",
    "            fake_test = G(Variable(z_extra))\n",
    "            vutils.save_image(fake_test.data, '%s/run-%d/images/extra/fake_samples_iter%03d_extra%01d.png' % (param.output_folder, run, gen_iterations/50, ext), normalize=True)\n",
    "            \n",
    "    # Setting up iterable\n",
    "    i=0\n",
    "    data_iter = iter(dataset)\n",
    "\n",
    "    while i<len(dataset):\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad=True\n",
    "\n",
    "        # Trick used in Wassertein GAN paper for more stable convergence\n",
    "        if gen_iterations <25 or gen_iterations %500 ==0:\n",
    "            N_critic = 100\n",
    "        else:\n",
    "            N_critic = param.n_critic\n",
    "\n",
    "        t=0\n",
    "        while t<N_critic and i < len(dataset):\n",
    "            # Update D\n",
    "            D.zero_grad()\n",
    "\n",
    "            # Clip weights\n",
    "            for p in D.parameters():\n",
    "                p.data.clamp_(param.clip,param.clip)\n",
    "\n",
    "            # Sample real data\n",
    "            real_images,labels = data_iter.__next__()\n",
    "            # Mostly necessaary for last one becaus if N might not be a multiple of batch size\n",
    "            current_batch_size = real_image.size(0)\n",
    "            if param.cuda:\n",
    "                real_images = real_images.cuda()\n",
    "\n",
    "            # Transfer batch of images to x\n",
    "            x.data.resize_as_(real_images).copy_(real_images)\n",
    "            # Discriminator Loss real\n",
    "            errD_real = D(x)\n",
    "            errD_real.backward(one)\n",
    "\n",
    "            # Sample fake data\n",
    "            # Note that z might be bigger than x here, this is done like this in Wassertein paper, but it could probably be changed\n",
    "            z.data.resize_(current_batch_size,param.z_size,1,1).normal_(0,1)\n",
    "            # Volatile requires less memory and make things sightly faster than detach(), so why not use it with DCGAN?\n",
    "            #Simply because we reuse the same fake images, but in WGAN we generate new fake images after training for a while the Discriminator\n",
    "            z_volatile = Variable(z.data,volatile=True)\n",
    "            x_fake = Variable(G(z_volatile).data)\n",
    "            # Discriminator Loss fake\n",
    "            errD_fake = D(x_fake)\n",
    "            errD_fake.backward(one_neg)\n",
    "\n",
    "            # Optimize\n",
    "            errD = (errD_real-errD_fake)\n",
    "            optimizerD.step()\n",
    "\n",
    "            # Iterate up\n",
    "            t = t+1\n",
    "            i = i+1\n",
    "\n",
    "        # Update G network\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        G.zero_grad()\n",
    "\n",
    "        # Sample fake data\n",
    "        z.data.resize_(param.batch_size,param.z_size,1,1).normal_(0,1)\n",
    "        x_fake = G(z)\n",
    "        # Generator Loss\n",
    "        errG = D(x_fake)\n",
    "        errG.backward(one)\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Log results so we can see them in TensorBoard after\n",
    "        log_value('errD',-errD.data[0],gen_iterations)\n",
    "        log_value('errG', errG.data[0],gen_iterations)\n",
    "\n",
    "        gen_iterations = gen_iterations + 1\n",
    "\n",
    "        if gen_iterations % 50 == 0:\n",
    "            end = time.time()\n",
    "            print('[%d] W_distance: %.4f Loss_G: %.4f time:%.4f' % (gen_iterations, -errD.data[0], errG.data[0], end - start))\n",
    "            print('[%d] W_distance: %.4f Loss_G: %.4f time:%.4f' % (gen_iterations, -errD.data[0], errG.data[0], end - start), file=log_output)\n",
    "        # Save models\n",
    "        if gen_iterations % 500 == 0:\n",
    "            torch.save(G.state_dict(), '%s/run-%d/models/G_%d.pth' % (param.output_folder, run, gen_iterations/50))\n",
    "            torch.save(D.state_dict(), '%s/run-%d/models/D_%d.pth' % (param.output_folder, run, gen_iterations/50))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e098fe7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--n_workers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of subprocess to use to load the data. Use at least two or the number of cpu cores - 1.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--gen_extra_images\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvery 50 generator iterations, generate additional images with \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m random fake cats.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/argparse.py:1827\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argv:\n\u001b[1;32m   1826\u001b[0m     msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munrecognized arguments: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/argparse.py:2581\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_usage(_sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m   2580\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/argparse.py:2568\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message:\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2568\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19dbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
