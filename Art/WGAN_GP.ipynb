{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7abc790",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 287)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:287\u001b[0;36m\u001b[0m\n\u001b[0;31m    for t in range(param.n_critic):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--image_size', type=int, default=64)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--n_colors', type=int, default=3)\n",
    "parser.add_argument('--z_size', type=int, default=100) # DCGAN paper original value\n",
    "parser.add_argument('--G_h_size', type=int, default=128, help='Number of hidden nodes in the Generator. Too small leads to bad results, too big blows up the GPU RAM.') # DCGAN paper original value\n",
    "parser.add_argument('--D_h_size', type=int, default=128, help='Number of hidden nodes in the Discriminator. Too small leads to bad results, too big blows up the GPU RAM.') # DCGAN paper original value\n",
    "parser.add_argument('--lr_D', type=float, default=.0001, help='Discriminator learning rate') # WGAN original value\n",
    "parser.add_argument('--lr_G', type=float, default=.0001, help='Generator learning rate')\n",
    "parser.add_argument('--n_iter', type=int, default=100000, help='Number of iterations')\n",
    "parser.add_argument('--n_critic', type=int, default=5, help='Number of training with D before training G') # WGAN original value\n",
    "parser.add_argument('--beta1', type=float, default=0, help='Adam betas[0], WGAN-GP paper recommends 0') # WGAN original value\n",
    "parser.add_argument('--beta2', type=float, default=.9, help='Adam betas[1], WGAN-GP paper recommends .90') # WGAN original value\n",
    "parser.add_argument('--penalty', type=float, default=10, help='Gradient penalty parameter for WGAN-GP')\n",
    "parser.add_argument('--SELU', type=bool, default=False, help='Using scaled exponential linear units (SELU) which are self-normalizing instead of ReLU with BatchNorm. This improves stability.')\n",
    "parser.add_argument('--seed', type=int)\n",
    "parser.add_argument('--input_folder', default='/home/alexia/Datasets/Meow_64x64', help='input folder')\n",
    "parser.add_argument('--output_folder', default='/home/alexia/Output/WGAN-GP', help='output folder')\n",
    "parser.add_argument('--G_load', default='', help='Full path to Generator model to load (ex: /home/output_folder/run-5/models/G_epoch_11.pth)')\n",
    "parser.add_argument('--D_load', default='', help='Full path to Discriminator model to load (ex: /home/output_folder/run-5/models/D_epoch_11.pth)')\n",
    "parser.add_argument('--cuda', type=bool, default=True, help='enables cuda')\n",
    "parser.add_argument('--n_gpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--gen_extra_images', type=int, default=0, help='Every 50 generator iterations, generate additional images with \"batch_size\" random fake cats.')\n",
    "param = parser.parse_args()\n",
    "\n",
    "## Imports\n",
    "\n",
    "# Time\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Check folder run-i for all i=0,1,... until it finds run-j which does not exists, then creates a new folder run-j\n",
    "import os\n",
    "run = 0\n",
    "\n",
    "base_dir = f\"{param.output_folder}/run-{run}\"\n",
    "while os.path.exists(base_dir):\n",
    "\trun += 1\n",
    "\tbase_dir = f\"{param.output_folder}/run-{run}\"\n",
    "os.mkdir(base_dir)\n",
    "logs_dir = f\"{base_dir}/logs\"\n",
    "os.mkdir(logs_dir)\n",
    "os.mkdir(f\"{base_dir}/images\")\n",
    "os.mkdir(f\"{base_dir}/models\")\n",
    "if param.gen_extra_images > 0:\n",
    "\tos.mkdir(f\"{base_dir}/images/extra\")\n",
    "\n",
    "# where we save the output\n",
    "log_output = open(f\"{logs_dir}/log.txt\", 'w')\n",
    "print(param)\n",
    "print(param, file=log_output)\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# For plotting the Loss of D and G using tensorboard\n",
    "from tensorboard_logger import configure, log_value\n",
    "configure(logs_dir, flush_secs=5)\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transf\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "if param.cuda:\n",
    "\timport torch.backends.cudnn as cudnn\n",
    "\tcudnn.benchmark = True\n",
    "\n",
    "# To see images\n",
    "from IPython.display import Image\n",
    "to_img = transf.ToPILImage()\n",
    "\n",
    "## Setting seed\n",
    "import random\n",
    "if param.seed is None:\n",
    "\tparam.seed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", param.seed)\n",
    "print(\"Random Seed: \", param.seed, file=log_output)\n",
    "random.seed(param.seed)\n",
    "torch.manual_seed(param.seed)\n",
    "if param.cuda:\n",
    "\ttorch.cuda.manual_seed_all(param.seed)\n",
    "\n",
    "## Transforming images\n",
    "trans = transf.Compose([\n",
    "\ttransf.Scale((param.image_size, param.image_size)),\n",
    "\t# This makes it into [0,1]\n",
    "\ttransf.ToTensor(),\n",
    "\t# This makes it into [-1,1] so tanh will work properly\n",
    "\ttransf.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "## Importing dataset\n",
    "data = dset.ImageFolder(root=param.input_folder, transform=trans)\n",
    "\n",
    "# Generate a random sample\n",
    "def generate_random_sample():\n",
    "\twhile True:\n",
    "\t\trandom_indexes = numpy.random.choice(data.__len__(), size=param.batch_size, replace=False)\n",
    "\t\tbatch = [data[i][0] for i in random_indexes]\n",
    "\t\tyield torch.stack(batch, 0)\n",
    "random_sample = generate_random_sample()\n",
    "\n",
    "## Models\n",
    "# The number of layers is implicitly determined by the image size\n",
    "# image_size = (4,8,16,32,64, 128, 256, 512, 1024) leads to n_layers = (1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
    "# The more layers the bigger the neural get so it's best to decrease G_h_size and D_h_size when the image input is bigger\n",
    "\n",
    "# DCGAN generator\n",
    "class DCGAN_G(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DCGAN_G, self).__init__()\n",
    "\t\tmain = torch.nn.Sequential()\n",
    "\n",
    "\t\t# We need to know how many layers we will use at the beginning\n",
    "\t\tmult = param.image_size // 8\n",
    "\n",
    "\t\t### Start block\n",
    "\t\t# Z_size random numbers\n",
    "\t\tmain.add_module('Start-ConvTranspose2d', torch.nn.ConvTranspose2d(param.z_size, param.G_h_size * mult, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "\t\tif param.SELU:\n",
    "\t\t\tmain.add_module('Start-SELU', torch.nn.SELU(inplace=True))\n",
    "\t\telse:\n",
    "\t\t\tmain.add_module('Start-BatchNorm2d', torch.nn.BatchNorm2d(param.G_h_size * mult))\n",
    "\t\t\tmain.add_module('Start-ReLU', torch.nn.ReLU())\n",
    "\t\t# Size = (G_h_size * mult) x 4 x 4\n",
    "\n",
    "\t\t### Middle block (Done until we reach ? x image_size/2 x image_size/2)\n",
    "\t\ti = 1\n",
    "\t\twhile mult > 1:\n",
    "\t\t\tmain.add_module('Middle-ConvTranspose2d [%d]' % i, torch.nn.ConvTranspose2d(param.G_h_size * mult, param.G_h_size * (mult//2), kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\t\tif param.SELU:\n",
    "\t\t\t\tmain.add_module('Middle-SELU [%d]' % i, torch.nn.SELU(inplace=True))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmain.add_module('Middle-BatchNorm2d [%d]' % i, torch.nn.BatchNorm2d(param.G_h_size * (mult//2)))\n",
    "\t\t\t\tmain.add_module('Middle-ReLU [%d]' % i, torch.nn.ReLU())\n",
    "\t\t\t# Size = (G_h_size * (mult/(2*i))) x 8 x 8\n",
    "\t\t\tmult = mult // 2\n",
    "\t\t\ti += 1\n",
    "\n",
    "\t\t### End block\n",
    "\t\t# Size = G_h_size x image_size/2 x image_size/2\n",
    "\t\tmain.add_module('End-ConvTranspose2d', torch.nn.ConvTranspose2d(param.G_h_size, param.n_colors, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\tmain.add_module('End-Tanh', torch.nn.Tanh())\n",
    "\t\t# Size = n_colors x image_size x image_size\n",
    "\t\tself.main = main\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tif isinstance(input.data, torch.cuda.FloatTensor) and param.n_gpu > 1:\n",
    "\t\t\toutput = torch.nn.parallel.data_parallel(self.main, input, range(param.n_gpu))\n",
    "\t\telse:\n",
    "\t\t\toutput = self.main(input)\n",
    "\t\treturn output\n",
    "\n",
    "# DCGAN discriminator (using somewhat the reverse of the generator)\n",
    "# Removed Batch Norm we can't backward on the gradients with BatchNorm2d\n",
    "class DCGAN_D(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(DCGAN_D, self).__init__()\n",
    "\t\tmain = torch.nn.Sequential()\n",
    "\n",
    "\t\t### Start block\n",
    "\t\t# Size = n_colors x image_size x image_size\n",
    "\t\tmain.add_module('Start-Conv2d', torch.nn.Conv2d(param.n_colors, param.D_h_size, kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\tif param.SELU:\n",
    "\t\t\tmain.add_module('Start-SELU', torch.nn.SELU(inplace=True))\n",
    "\t\telse:\n",
    "\t\t\tmain.add_module('Start-LeakyReLU', torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\t\timage_size_new = param.image_size // 2\n",
    "\t\t# Size = D_h_size x image_size/2 x image_size/2\n",
    "\n",
    "\t\t### Middle block (Done until we reach ? x 4 x 4)\n",
    "\t\tmult = 1\n",
    "\t\ti = 0\n",
    "\t\twhile image_size_new > 4:\n",
    "\t\t\tmain.add_module('Middle-Conv2d [%d]' % i, torch.nn.Conv2d(param.D_h_size * mult, param.D_h_size * (2*mult), kernel_size=4, stride=2, padding=1, bias=False))\n",
    "\t\t\tif param.SELU:\n",
    "\t\t\t\tmain.add_module('Middle-SELU [%d]' % i, torch.nn.SELU(inplace=True))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmain.add_module('Middle-LeakyReLU [%d]' % i, torch.nn.LeakyReLU(0.2, inplace=True))\n",
    "\t\t\t# Size = (D_h_size*(2*i)) x image_size/(2*i) x image_size/(2*i)\n",
    "\t\t\timage_size_new = image_size_new // 2\n",
    "\t\t\tmult = mult*2\n",
    "\t\t\ti += 1\n",
    "\n",
    "\t\t### End block\n",
    "\t\t# Size = (D_h_size * mult) x 4 x 4\n",
    "\t\tmain.add_module('End-Conv2d', torch.nn.Conv2d(param.D_h_size * mult, 1, kernel_size=4, stride=1, padding=0, bias=False))\n",
    "\t\t# Note: No more sigmoid in WGAN, we take the mean now\n",
    "\t\t# Size = 1 x 1 x 1 (Is a real cat or not?)\n",
    "\t\tself.main = main\n",
    "\n",
    "\tdef forward(self, input):\n",
    "\t\tif isinstance(input.data, torch.cuda.FloatTensor) and param.n_gpu > 1:\n",
    "\t\t\toutput = torch.nn.parallel.data_parallel(self.main, input, range(param.n_gpu))\n",
    "\t\telse:\n",
    "\t\t\toutput = self.main(input)\n",
    "\t\t# From batch_size x 1 x 1 (DCGAN used the sigmoid instead before)\n",
    "\t\t# Convert from batch_size x 1 x 1 to batch_size\n",
    "\t\treturn output.view(-1)\n",
    "\n",
    "## Weights init function, DCGAN use 0.02 std\n",
    "def weights_init(m):\n",
    "\tclassname = m.__class__.__name__\n",
    "\tif classname.find('Conv') != -1:\n",
    "\t\tm.weight.data.normal_(0.0, 0.02)\n",
    "\telif classname.find('BatchNorm') != -1:\n",
    "\t\t# Estimated variance, must be around 1\n",
    "\t\tm.weight.data.normal_(1.0, 0.02)\n",
    "\t\t# Estimated mean, must be around 0\n",
    "\t\tm.bias.data.fill_(0)\n",
    "\n",
    "## Initialization\n",
    "G = DCGAN_G()\n",
    "D = DCGAN_D()\n",
    "\n",
    "# Initialize weights\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "# Load existing models\n",
    "if param.G_load != '':\n",
    "\tG.load_state_dict(torch.load(param.G_load))\n",
    "if param.D_load != '':\n",
    "\tD.load_state_dict(torch.load(param.D_load))\n",
    "\n",
    "print(G)\n",
    "print(G, file=log_output)\n",
    "print(D)\n",
    "print(D, file=log_output)\n",
    "\n",
    "# Soon to be variables\n",
    "x = torch.FloatTensor(param.batch_size, param.n_colors, param.image_size, param.image_size)\n",
    "# Weighted sum of fake and real image, for gradient penalty\n",
    "x_both = torch.FloatTensor(param.batch_size, param.n_colors, param.image_size, param.image_size)\n",
    "z = torch.FloatTensor(param.batch_size, param.z_size, 1, 1)\n",
    "# Uniform weight\n",
    "u = torch.FloatTensor(param.batch_size, 1, 1, 1)\n",
    "# This is to see during training, size and values won't change\n",
    "z_test = torch.FloatTensor(param.batch_size, param.z_size, 1, 1).normal_(0, 1)\n",
    "# For the gradients, we need to specify which one we want and want them all\n",
    "grad_outputs = torch.ones(param.batch_size)\n",
    "one = torch.FloatTensor([1])\n",
    "one_neg = one * -1\n",
    "\n",
    "# Everything cuda\n",
    "if param.cuda:\n",
    "\tG = G.cuda()\n",
    "\tD = D.cuda()\n",
    "\tx = x.cuda()\n",
    "\tz = z.cuda()\n",
    "\tu = u.cuda()\n",
    "\tz_test = z_test.cuda()\n",
    "\tgrad_outputs = grad_outputs.cuda()\n",
    "\tone, one_neg = one.cuda(), one_neg.cuda()\n",
    "\n",
    "# Now Variables\n",
    "x = Variable(x)\n",
    "z = Variable(z)\n",
    "z_test = Variable(z_test)\n",
    "\n",
    "# Optimizer\n",
    "optimizerD = torch.optim.Adam(D.parameters(), lr=param.lr_D, betas=(param.beta1, param.beta2))\n",
    "optimizerG = torch.optim.Adam(G.parameters(), lr=param.lr_G, betas=(param.beta1, param.beta2))\n",
    "\n",
    "## Fitting model\n",
    "for i in range(param.n_iter):\n",
    "\n",
    "\t# Fake images saved\n",
    "\tif i % 50 == 0:\n",
    "\t\tfake_test = G(z_test)\n",
    "\t\tvutils.save_image(fake_test.data, '%s/run-%d/images/fake_samples_iter%03d.png' % (param.output_folder, run, i/50), normalize=True)\n",
    "\t\tfor ext in range(param.gen_extra_images):\n",
    "\t\t\tz_extra = torch.FloatTensor(param.batch_size, param.z_size, 1, 1).normal_(0, 1)\n",
    "\t\t\tif param.cuda:\n",
    "\t\t\t\tz_extra = z_extra.cuda()\n",
    "\t\t\tfake_test = G(Variable(z_extra))\n",
    "\t\t\tvutils.save_image(fake_test.data, '%s/run-%d/images/extra/fake_samples_iter%03d_extra%01d.png' % (param.output_folder, run, i/50, ext), normalize=True)\n",
    "\n",
    "\tfor p in D.parameters():\n",
    "\t\tp.requires_grad = True\n",
    "        \n",
    "    for t in range(param.n_critic):\n",
    "        # Update D network\n",
    "        D.zero_grad()\n",
    "        \n",
    "        #Sample real data\n",
    "        real_images = random_sample.__next__()\n",
    "        if param.cuda:\n",
    "            real_images = real_images.cuda()\n",
    "        x.data.copy_(real_images)\n",
    "        # Discriminator Loss real\n",
    "        errD_real = D(x)\n",
    "        errD_real = errD_real.mean()\n",
    "        errD_real.backward(one_neg)\n",
    "        \n",
    "        # Sample fake data\n",
    "        z.data.norml_(0,1)\n",
    "\t\t# Volatile requires less memory and make things sightly faster than detach(), so wy not use it with DCGAN?\n",
    "\t\t# Simply because we reuse the same fake images, but in WGAN we generate new fake images after training for a while the Discriminator\n",
    "        z_volatile = Variable(z.data,volatile=True)\n",
    "        x_fake = Variable(G(z_volatile).data)\n",
    "        # Discriminator Loss fake\n",
    "        errD_fake = D(x_fake)\n",
    "        errD_fake = errD_fake.mean()\n",
    "        errD_fake.backward(one)\n",
    "        \n",
    "        # Gradient penalty\n",
    "        u.uniform_(0,1)\n",
    "        x_both = x.data*u + x_fake.data*(1-u)\n",
    "        if param.cuda:\n",
    "            x_both = x_both.cuda()\n",
    "        # We only want the gradients with respect to x_both\n",
    "        x_both = Variable(x_both,requires_grad=True)\n",
    "        grad = torch.autograd.grad(outputs=D(x_both),inputs=x_both,grad_outputs=grad_outputs,retain_graph=True,create_graph=True,only_inputs=True)[0]\n",
    "        # We need to norm 3 times(over n_colors x image_size x image_size) to get only a vector of size \"batch_size\"\n",
    "        grad_penalty = param.penalty*((grad.norm(2,1).norm(2,1).norm(2,1)-1)**2).mean()\n",
    "        grad_penalty.backward()\n",
    "        # Optimize\n",
    "        errD_penalty = errD_fake-errD_real+grad_penalty\n",
    "        errD = errD_fake - errD_real\n",
    "        optimizerD.step()\n",
    "        \n",
    "    \n",
    "    # Update G network:\n",
    "    for p in D.parameters():\n",
    "        p.requires_grad=False\n",
    "        \n",
    "    G.zero_grad()\n",
    "    \n",
    "    # Sample fake data\n",
    "    z.data.normal_(0,1)\n",
    "    x_fake = G(z)\n",
    "    # Generator Loss\n",
    "    errG = D(x_fake)\n",
    "    errG = errG.mean()\n",
    "    errG.backward(one_neg)\n",
    "    optimizerG.step()\n",
    "    \n",
    "    # Log results so we can see them in TensorBoard after\n",
    "    log_value('errD',errD.data[0],i)\n",
    "    log_value('errD_penalty',errD_penalty.data[0],i)\n",
    "    log_value('errG',errG.data[0],i)\n",
    "    \n",
    "\tif i % 50 == 0:\n",
    "\t\tprint('[i=%d] W_distance: %.4f W_distance_penalty: %.4f Loss_G: %.4f' % (i, errD.data[0], errD_penalty.data[0], errG.data[0]))\n",
    "\t\tprint('[i=%d] W_distance: %.4f W_distance_penalty: %.4f Loss_G: %.4f' % (i, errD.data[0], errD_penalty.data[0], errG.data[0]), file=log_output)\n",
    "\t# Save models\n",
    "\tif i % 500 == 0:\n",
    "\t\ttorch.save(G.state_dict(), '%s/run-%d/models/G_%d.pth' % (param.output_folder, run, i))\n",
    "\t\ttorch.save(D.state_dict(), '%s/run-%d/models/D_%d.pth' % (param.output_folder, run, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98071c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
